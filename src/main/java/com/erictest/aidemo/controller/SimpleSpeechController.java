package com.erictest.aidemo.controller;

import java.io.File;
import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.nio.file.StandardCopyOption;
import java.util.HashMap;
import java.util.Map;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Controller;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.ResponseBody;
import org.springframework.web.multipart.MultipartFile;

import com.erictest.aidemo.service.SphinxSpeechRecognitionService;
import com.erictest.aidemo.service.WhisperSpeechRecognitionService;

/**
 * æ™ºèƒ½èªéŸ³è™•ç†æ§åˆ¶å™¨ - æ•´åˆ OpenAI Whisper
 */
@Controller
@RequestMapping("/speech")
public class SimpleSpeechController {

    @Autowired
    private SphinxSpeechRecognitionService sphinxSpeechService;

    @Autowired
    private WhisperSpeechRecognitionService whisperSpeechService;

    // è¨­å®šéŸ³é »æª”æ¡ˆä¸Šå‚³ç›®éŒ„
    private static final String UPLOAD_DIR = "uploads/audio/";

    /**
     * é¡¯ç¤ºèªéŸ³è™•ç†é é¢
     */
    @GetMapping("/demo")
    public String speechDemo() {
        return "speech-demo";
    }

    /**
     * é¡¯ç¤º Sphinx å¼•æ“è³‡è¨Š
     */
    @GetMapping("/engine-info")
    @ResponseBody
    public Map<String, Object> getEngineInfo() {
        Map<String, Object> response = new HashMap<>();

        // åˆå§‹åŒ– Sphinx æœå‹™ï¼ˆå¦‚æœå°šæœªåˆå§‹åŒ–ï¼‰
        if (!sphinxSpeechService.isReady()) {
            sphinxSpeechService.initialize();
        }

        response.put("success", true);
        response.put("engineInfo", sphinxSpeechService.getEngineInfo());
        response.put("recommendations", sphinxSpeechService.getAudioRecommendations());
        response.put("isReady", sphinxSpeechService.isReady());

        return response;
    }

    /**
     * æ¸¬è©¦API - è¿”å›å›ºå®šçš„æ¸¬è©¦æ•¸æ“š
     */
    @PostMapping("/api/test-speech-to-text")
    @ResponseBody
    public Map<String, Object> testSpeechToText() {
        Map<String, Object> response = new HashMap<>();
        System.out.println("ğŸ“ æ”¶åˆ°æ¸¬è©¦èªéŸ³è½‰æ–‡å­—è«‹æ±‚");

        response.put("success", true);
        response.put("message", "èªéŸ³è½‰æ–‡å­—å®Œæˆ");
        response.put("data", Map.of(
                "recognizedText", "é€™æ˜¯æ¸¬è©¦è­˜åˆ¥çµæœï¼šHello World! é€™æ˜¯èªéŸ³è½‰æ–‡å­—çš„æ¸¬è©¦å…§å®¹ã€‚",
                "fileName", "test_audio.mp3",
                "fileSize", 123456L,
                "confidence", 0.98
        ));

        System.out.println("ğŸ¯ è¿”å›æ¸¬è©¦æ•¸æ“šï¼š" + response);
        return response;
    }

    /**
     * èªéŸ³è½‰æ–‡å­— API - ä½¿ç”¨ OpenAI Whisper å¼•æ“
     */
    @PostMapping("/api/speech-to-text")
    @ResponseBody
    public Map<String, Object> speechToText(@RequestParam("audioFile") MultipartFile audioFile) {
        Map<String, Object> response = new HashMap<>();
        System.out.println("ğŸ¤ æ”¶åˆ°èªéŸ³è½‰æ–‡å­—è«‹æ±‚ï¼Œæª”æ¡ˆåç¨±: " + audioFile.getOriginalFilename());
        System.out.println("ğŸ“Š æª”æ¡ˆå¤§å°: " + audioFile.getSize() + " bytes");
        System.out.println("ğŸ“‹ æª”æ¡ˆé¡å‹: " + audioFile.getContentType());

        try {
            // å»ºç«‹ä¸Šå‚³ç›®éŒ„
            createUploadDirectoryIfNotExists();

            // é©—è­‰éŸ³é »æª”æ¡ˆ
            String validationResult = validateAudioFile(audioFile);
            if (validationResult != null) {
                System.out.println("âŒ æª”æ¡ˆé©—è­‰å¤±æ•—: " + validationResult);
                response.put("success", false);
                response.put("message", validationResult);
                return response;
            }
            System.out.println("âœ… æª”æ¡ˆé©—è­‰é€šé");

            // ä¿å­˜éŸ³é »æª”æ¡ˆ
            String fileName = generateFileName("audio", audioFile.getOriginalFilename());
            File savedFile = saveFileAndGetFile(audioFile, fileName);
            System.out.println("ğŸ’¾ æª”æ¡ˆå·²ä¿å­˜: " + fileName);

            // å„ªå…ˆä½¿ç”¨ OpenAI Whisper é€²è¡ŒèªéŸ³è­˜åˆ¥
            Map<String, Object> recognitionResult;
            try {
                recognitionResult = whisperSpeechService.recognizeFromFile(savedFile);
                System.out.println("ğŸ¤– Whisper è­˜åˆ¥çµæœ: " + recognitionResult);
            } catch (Exception whisperError) {
                System.out.println("âš ï¸ Whisper æœå‹™ä¸å¯ç”¨ï¼Œå›é€€åˆ° Sphinx: " + whisperError.getMessage());
                recognitionResult = sphinxSpeechService.recognizeFromFile(savedFile);
                System.out.println("ğŸ”¤ Sphinx è­˜åˆ¥çµæœ: " + recognitionResult);
            }

            if ((Boolean) recognitionResult.get("success")) {
                String engineName = (String) recognitionResult.getOrDefault("engine", "èªéŸ³è­˜åˆ¥å¼•æ“");

                response.put("success", true);
                response.put("message", "èªéŸ³è½‰æ–‡å­—å®Œæˆ (" + engineName + ")");
                response.put("data", Map.of(
                        "recognizedText", recognitionResult.get("recognizedText"),
                        "fileName", fileName,
                        "fileSize", audioFile.getSize(),
                        "confidence", recognitionResult.get("confidence"),
                        "engine", engineName,
                        "audioInfo", recognitionResult.getOrDefault("audioInfo", new HashMap<>()),
                        "processingTime", recognitionResult.getOrDefault("processingTime", "N/A"),
                        "whisperDetails", recognitionResult.getOrDefault("whisperDetails", new HashMap<>()),
                        "note", recognitionResult.getOrDefault("note", "")
                ));
            } else {
                // å¦‚æœæ‰€æœ‰æœå‹™éƒ½å¤±æ•—ï¼Œå›é€€åˆ°åŸºç¤æ¨¡æ“¬
                String recognizedText = simulateSpeechToText(audioFile);
                response.put("success", true);
                response.put("message", "èªéŸ³è½‰æ–‡å­—å®Œæˆ (åŸºç¤æ¨¡å¼)");
                response.put("data", Map.of(
                        "recognizedText", recognizedText,
                        "fileName", fileName,
                        "fileSize", audioFile.getSize(),
                        "confidence", 0.75,
                        "engine", "åŸºç¤æ¨¡æ“¬å¼•æ“"
                ));
            }

            System.out.println("âœ… èªéŸ³è½‰æ–‡å­—è™•ç†å®Œæˆï¼Œæº–å‚™è¿”å›çµæœ");

        } catch (Exception e) {
            System.err.println("âŒ èªéŸ³è½‰æ–‡å­—è™•ç†å¤±æ•—: " + e.getMessage());
            e.printStackTrace();
            response.put("success", false);
            response.put("message", "èªéŸ³è½‰æ–‡å­—å¤±æ•—ï¼š" + e.getMessage());
        }

        return response;
    }

    /**
     * æ–‡å­—è½‰èªéŸ³ API
     */
    @PostMapping("/api/text-to-speech")
    @ResponseBody
    public Map<String, Object> textToSpeech(@RequestParam("text") String text,
            @RequestParam(value = "language", defaultValue = "zh-TW") String language,
            @RequestParam(value = "voice", defaultValue = "female") String voice) {
        Map<String, Object> response = new HashMap<>();

        try {
            // é©—è­‰æ–‡å­—è¼¸å…¥
            if (text == null || text.trim().isEmpty()) {
                response.put("success", false);
                response.put("message", "è«‹è¼¸å…¥è¦è½‰æ›çš„æ–‡å­—");
                return response;
            }

            if (text.length() > 5000) {
                response.put("success", false);
                response.put("message", "æ–‡å­—é•·åº¦ä¸èƒ½è¶…é5000å­—å…ƒ");
                return response;
            }

            // å»ºç«‹ä¸Šå‚³ç›®éŒ„
            createUploadDirectoryIfNotExists();

            // æ¨¡æ“¬æ–‡å­—è½‰èªéŸ³
            String audioFileName = simulateTextToSpeech(text, language, voice);

            response.put("success", true);
            response.put("message", "æ–‡å­—è½‰èªéŸ³å®Œæˆ");
            response.put("data", Map.of(
                    "audioUrl", "/speech/audio/" + audioFileName,
                    "fileName", audioFileName,
                    "text", text,
                    "language", language,
                    "voice", voice,
                    "duration", Math.min(text.length() * 0.1, 60) // æ¨¡æ“¬éŸ³é »é•·åº¦
            ));

        } catch (Exception e) {
            response.put("success", false);
            response.put("message", "æ–‡å­—è½‰èªéŸ³å¤±æ•—ï¼š" + e.getMessage());
        }

        return response;
    }

    private void createUploadDirectoryIfNotExists() throws IOException {
        Path uploadPath = Paths.get(UPLOAD_DIR);
        if (!Files.exists(uploadPath)) {
            Files.createDirectories(uploadPath);
        }
    }

    private String validateAudioFile(MultipartFile audioFile) {
        if (audioFile.isEmpty()) {
            return "âŒ è«‹é¸æ“‡éŸ³é »æª”æ¡ˆ";
        }

        long maxSize = 10 * 1024 * 1024; // 10MB
        if (audioFile.getSize() > maxSize) {
            return "âŒ éŸ³é »æª”æ¡ˆéå¤§ï¼ˆè¶…é 10MBï¼‰";
        }

        String contentType = audioFile.getContentType();
        if (contentType == null
                || (!contentType.equals("audio/wav")
                && !contentType.equals("audio/mp3")
                && !contentType.equals("audio/mpeg")
                && !contentType.equals("audio/ogg")
                && !contentType.equals("audio/webm")
                && !contentType.startsWith("audio/"))) {
            return "âŒ è«‹ä¸Šå‚³æœ‰æ•ˆçš„éŸ³é »æª”æ¡ˆï¼ˆWAVã€MP3ã€OGG ç­‰æ ¼å¼ï¼‰";
        }

        return null;
    }

    private String generateFileName(String prefix, String originalFilename) {
        String timestamp = String.valueOf(System.currentTimeMillis());
        String extension = getFileExtension(originalFilename);
        return String.format("%s_%s%s", prefix, timestamp, extension);
    }

    private String getFileExtension(String filename) {
        if (filename != null && filename.lastIndexOf(".") > 0) {
            return filename.substring(filename.lastIndexOf("."));
        }
        return ".wav";
    }

    private void saveFile(MultipartFile file, String fileName) throws IOException {
        Path targetLocation = Paths.get(UPLOAD_DIR + fileName);
        Files.copy(file.getInputStream(), targetLocation, StandardCopyOption.REPLACE_EXISTING);
    }

    /**
     * ä¿å­˜æª”æ¡ˆä¸¦è¿”å› File å°è±¡ä¾› Sphinx ä½¿ç”¨
     */
    private File saveFileAndGetFile(MultipartFile file, String fileName) throws IOException {
        Path targetLocation = Paths.get(UPLOAD_DIR + fileName);
        Files.copy(file.getInputStream(), targetLocation, StandardCopyOption.REPLACE_EXISTING);
        return targetLocation.toFile();
    }

    private String simulateSpeechToText(MultipartFile audioFile) {
        String fileName = audioFile.getOriginalFilename();
        if (fileName != null && fileName.toLowerCase().contains("hello")) {
            return "æ‚¨å¥½ï¼Œæ­¡è¿ä½¿ç”¨èªéŸ³è­˜åˆ¥åŠŸèƒ½ï¼";
        } else if (fileName != null && fileName.toLowerCase().contains("test")) {
            return "é€™æ˜¯ä¸€å€‹èªéŸ³è½‰æ–‡å­—çš„æ¸¬è©¦ã€‚";
        } else {
            return "é€™æ˜¯ä¸€æ®µç¤ºä¾‹èªéŸ³å…§å®¹ï¼Œå¯¦éš›ä½¿ç”¨æ™‚æœƒèª¿ç”¨ Google Cloud Speech-to-Text API é€²è¡Œè­˜åˆ¥ã€‚æ‚¨å¯ä»¥èªªä»»ä½•å…§å®¹ï¼Œç³»çµ±æœƒå°‡å…¶è½‰æ›ç‚ºæ–‡å­—ã€‚";
        }
    }

    private String simulateTextToSpeech(String text, String language, String voice) throws IOException {
        String timestamp = String.valueOf(System.currentTimeMillis());
        String audioFileName = String.format("tts_%s_%s_%s.mp3", language, voice, timestamp);

        // å‰µå»ºä¸€å€‹ç°¡å–®çš„HTMLéŸ³é »æç¤ºæª”æ¡ˆ
        String htmlContent = String.format(
                """
            <!DOCTYPE html>
            <html>
            <head><title>æ–‡å­—è½‰èªéŸ³æ¨¡æ“¬</title></head>
            <body>
                <h3>æ¨¡æ“¬çš„æ–‡å­—è½‰èªéŸ³çµæœ</h3>
                <p><strong>åŸå§‹æ–‡å­—ï¼š</strong> %s</p>
                <p><strong>èªè¨€ï¼š</strong> %s</p>
                <p><strong>èªéŸ³é¡å‹ï¼š</strong> %s</p>
                <p style="color: #666;">å¯¦éš›éƒ¨ç½²æ™‚ï¼Œé€™è£¡æœƒæ˜¯ Google Cloud ç”Ÿæˆçš„çœŸå¯¦éŸ³é »æª”æ¡ˆ</p>
                <script>
                    // ä½¿ç”¨ç€è¦½å™¨çš„èªéŸ³åˆæˆAPIä½œç‚ºæ¼”ç¤º
                    const utterance = new SpeechSynthesisUtterance('%s');
                    utterance.lang = '%s';
                    speechSynthesis.speak(utterance);
                </script>
            </body>
            </html>
            """,
                text.replace("'", "\\'"), language, voice, text.replace("'", "\\'"),
                language.equals("zh-TW") ? "zh-CN" : "en-US"
        );

        // ä¿å­˜HTMLæª”æ¡ˆåˆ°éŸ³é »ç›®éŒ„
        Path audioPath = Paths.get(UPLOAD_DIR + audioFileName + ".html");
        Files.write(audioPath, htmlContent.getBytes());

        return audioFileName;
    }
}
