#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenAI Whisper èªéŸ³è½‰æ–‡å­—æ ¸å¿ƒç¨‹å¼ç¤ºä¾‹
å±•ç¤º Python å¦‚ä½•è™•ç†èªéŸ³ç”Ÿæˆæ–‡å­—
"""

import os
import sys
from pathlib import Path

import numpy as np
import torch
import whisper


def whisper_core_demo(audio_file_path):
    """
    å±•ç¤º Whisper æ ¸å¿ƒèªéŸ³è½‰æ–‡å­—æµç¨‹
    """
    print("=" * 60)
    print("ğŸ¤ OpenAI Whisper Python èªéŸ³è™•ç†æ ¸å¿ƒç¨‹å¼")
    print("=" * 60)
    
    # ç¬¬ 1 æ­¥ï¼šè¼‰å…¥ Whisper æ¨¡å‹
    print("\nğŸ“¥ ç¬¬ 1 æ­¥ï¼šè¼‰å…¥ Whisper AI æ¨¡å‹...")
    model = whisper.load_model("base")
    print(f"âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸï¼š{model}")
    print(f"ğŸ§  æ¨¡å‹ç¶­åº¦ï¼š{model.dims}")
    
    # ç¬¬ 2 æ­¥ï¼šéŸ³è¨Šæª”æ¡ˆé è™•ç†
    print("\nğŸ”Š ç¬¬ 2 æ­¥ï¼šéŸ³è¨Šæª”æ¡ˆè¼‰å…¥èˆ‡é è™•ç†...")
    if not os.path.exists(audio_file_path):
        print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨ï¼š{audio_file_path}")
        return
    
    # ä½¿ç”¨ Whisper çš„éŸ³è¨Šè¼‰å…¥å‡½æ•¸
    audio = whisper.load_audio(audio_file_path)
    print(f"ğŸ“Š éŸ³è¨Šè³‡æ–™å½¢ç‹€ï¼š{audio.shape}")
    print(f"ğŸµ éŸ³è¨Šé•·åº¦ï¼š{len(audio) / whisper.audio.SAMPLE_RATE:.2f} ç§’")
    print(f"âš¡ å–æ¨£ç‡ï¼š{whisper.audio.SAMPLE_RATE} Hz")
    
    # ç¬¬ 3 æ­¥ï¼šéŸ³è¨Šæ­£è¦åŒ–èˆ‡å¡«å……
    print("\nğŸ”§ ç¬¬ 3 æ­¥ï¼šéŸ³è¨Šæ­£è¦åŒ–è™•ç†...")
    audio = whisper.pad_or_trim(audio)
    print(f"ğŸ“ è™•ç†å¾ŒéŸ³è¨Šé•·åº¦ï¼š{len(audio) / whisper.audio.SAMPLE_RATE:.2f} ç§’")
    
    # ç¬¬ 4 æ­¥ï¼šç”Ÿæˆæ¢…çˆ¾é »è­œåœ–
    print("\nğŸ“ˆ ç¬¬ 4 æ­¥ï¼šç”Ÿæˆæ¢…çˆ¾é »è­œåœ–...")
    mel = whisper.log_mel_spectrogram(audio, model.dims.n_mels)
    print(f"ğŸŒŠ æ¢…çˆ¾é »è­œå½¢ç‹€ï¼š{mel.shape}")
    
    # ç¬¬ 5 æ­¥ï¼šèªè¨€æª¢æ¸¬
    print("\nğŸŒ ç¬¬ 5 æ­¥ï¼šè‡ªå‹•èªè¨€æª¢æ¸¬...")
    mel = mel.to(model.device)
    _, probs = model.detect_language(mel)
    detected_lang = max(probs, key=probs.get)
    confidence = probs[detected_lang]
    print(f"ğŸ¯ æª¢æ¸¬åˆ°èªè¨€ï¼š{detected_lang} (ä¿¡å¿ƒåº¦ï¼š{confidence:.2%})")
    
    # ç¬¬ 6 æ­¥ï¼šèªéŸ³è½‰æ–‡å­— (æ ¸å¿ƒæ­¥é©Ÿ)
    print("\nğŸš€ ç¬¬ 6 æ­¥ï¼šåŸ·è¡ŒèªéŸ³è½‰æ–‡å­—...")
    options = whisper.DecodingOptions(
        language="zh",  # æŒ‡å®šä¸­æ–‡
        fp16=False      # CPU ä½¿ç”¨ FP32
    )
    
    result = whisper.decode(model, mel, options)
    
    # ç¬¬ 7 æ­¥ï¼šçµæœè¼¸å‡º
    print("\nğŸ“ ç¬¬ 7 æ­¥ï¼šèªéŸ³è­˜åˆ¥çµæœ")
    print("-" * 40)
    print(f"ğŸ¯ è­˜åˆ¥æ–‡å­—ï¼š{result.text}")
    print(f"ğŸ“Š å¹³å‡æ¦‚ç‡ï¼š{result.avg_logprob:.4f}")
    print(f"ğŸ”¢ ç„¡èªéŸ³æ¦‚ç‡ï¼š{result.no_speech_prob:.4f}")
    print(f"âš¡ æº«åº¦ï¼š{result.temperature}")
    
    # ä½¿ç”¨å®Œæ•´çš„ transcribe å‡½æ•¸ (æ›´é«˜ç´šçš„åŠŸèƒ½)
    print("\nğŸŒŸ ä½¿ç”¨å®Œæ•´ transcribe å‡½æ•¸:")
    full_result = whisper.transcribe(model, audio_file_path, language="zh")
    
    print(f"ğŸ“‹ å®Œæ•´è­˜åˆ¥æ–‡å­—ï¼š")
    print(full_result["text"])
    
    if "segments" in full_result:
        print(f"\nâ±ï¸ æ™‚é–“è»¸è³‡è¨Šï¼š")
        for i, segment in enumerate(full_result["segments"][:3]):  # åªé¡¯ç¤ºå‰3å€‹ç‰‡æ®µ
            print(f"  {i+1}. [{segment['start']:.1f}s - {segment['end']:.1f}s] {segment['text']}")
    
    return full_result

def show_whisper_architecture():
    """
    å±•ç¤º Whisper çš„ç¥ç¶“ç¶²è·¯æ¶æ§‹
    """
    print("\n" + "=" * 60)
    print("ğŸ§  Whisper AI ç¥ç¶“ç¶²è·¯æ¶æ§‹")
    print("=" * 60)
    
    model = whisper.load_model("base")
    
    print(f"ğŸ—ï¸ æ¨¡å‹é¡å‹ï¼š{type(model)}")
    print(f"ğŸ“Š åƒæ•¸æ•¸é‡ï¼š{sum(p.numel() for p in model.parameters()):,}")
    print(f"ğŸ¯ è©å½™è¡¨å¤§å°ï¼š{model.dims.n_vocab:,}")
    print(f"ğŸ”¤ æ–‡å­—é•·åº¦ï¼š{model.dims.n_text_ctx}")
    print(f"ğŸµ éŸ³è¨Šé•·åº¦ï¼š{model.dims.n_audio_ctx}")
    print(f"ğŸŒŠ æ¢…çˆ¾é »ç‡æ•¸ï¼š{model.dims.n_mels}")
    
    print("\nğŸ“‹ æ¨¡å‹çµæ§‹çµ„ä»¶ï¼š")
    for name, module in model.named_children():
        print(f"  â€¢ {name}: {type(module).__name__}")

def main():
    """ä¸»ç¨‹å¼"""
    print("ğŸ¯ Python Whisper èªéŸ³è™•ç†ç¨‹å¼ç¤ºç¯„")
    
    # æª¢æŸ¥æ˜¯å¦æœ‰éŸ³è¨Šæª”æ¡ˆåƒæ•¸
    if len(sys.argv) > 1:
        audio_file = sys.argv[1]
    else:
        # ä½¿ç”¨é è¨­çš„æ¸¬è©¦æª”æ¡ˆ
        audio_dir = Path("uploads/audio")
        if audio_dir.exists():
            audio_files = list(audio_dir.glob("*.mp3")) + list(audio_dir.glob("*.wav"))
            if audio_files:
                audio_file = str(audio_files[0])
                print(f"ğŸ“ ä½¿ç”¨é è¨­éŸ³è¨Šæª”æ¡ˆï¼š{audio_file}")
            else:
                print("âŒ æ‰¾ä¸åˆ°éŸ³è¨Šæª”æ¡ˆ")
                return
        else:
            print("âŒ uploads/audio ç›®éŒ„ä¸å­˜åœ¨")
            return
    
    # åŸ·è¡ŒèªéŸ³è½‰æ–‡å­—ç¤ºç¯„
    result = whisper_core_demo(audio_file)
    
    # é¡¯ç¤ºæ¶æ§‹è³‡è¨Š
    show_whisper_architecture()
    
    print("\n" + "=" * 60)
    print("âœ… Python Whisper èªéŸ³è™•ç†ç¨‹å¼ç¤ºç¯„å®Œæˆ")
    print("=" * 60)

if __name__ == "__main__":
    main()
